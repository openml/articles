<!DOCTYPE html>
<html>
  <head>
    <title>OpenML: Connecting R to the Machine Learning Platform OpenML</title>
    <meta charset="utf-8">
    <meta name="author" content="Giuseppe Casalicchio, Bernd Bischl, Heidi Seibold, Joaquin Vanschoren" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# OpenML: Connecting R to the Machine Learning Platform OpenML
## whyR? 2018 tutorial - <a href="https://tiny.cc/whyR2018" class="uri">https://tiny.cc/whyR2018</a>
### Giuseppe Casalicchio, Bernd Bischl, Heidi Seibold, Joaquin Vanschoren
### <em>If you havenâ€™t done so yet, create an account on OpenML.org, and install the OpenML R package and either packages farff or RWeka</em>

---

&lt;!-- For this to work, install xaringan (devtools::install_github('yihui/xaringan')) --&gt;



---
class:center,middle
# Intro to mlr  

---

## Intro to mlr 
&lt;!-- [15 minutes, Bernd] --&gt;


mlr = General umbrella package for ML in R with standardized interface

&lt;img src="slides_tutorial_files/mlr.jpg" width="800px" /&gt;
- Project home page: https://github.com/mlr-org/mlr
- 8-10 main developers, quite a few contributors
- Extensive online tutorial available, look there first
- Can ask questions in the github issue tracker

Install for the following examples:

```r
install.packages(c("randomForest", "kernlab"))
```
`mlr` is atomatically installed when installing `OpenML`

---

## Intro to mlr 
- Classification, regression, survival, clustering, cost-sensitive, multilabel
- Includes &gt; 160 basic learning algorithms
- Unified interface for the basic building blocks: 
  tasks, learners, resampling, hyperparameters
- Reflections: nearly all objects are queryable, i.e. you can ask for their properties and program on them
- Programmed in an OO fashion in S3 (everything is an object)
- Makes extensions and generic algorithms easy
&lt;img src="slides_tutorial_files/ml_abstraction-crop.png" width="500px" /&gt;

---


### mlr - Train, predict, performance

```r
task = makeClassifTask(data = iris, target = "Species")
print(task)
```

```
## Supervised task: iris
## Type: classif
## Target: Species
## Observations: 150
## Features:
##    numerics     factors     ordered functionals 
##           4           0           0           0 
## Missings: FALSE
## Has weights: FALSE
## Has blocking: FALSE
## Has coordinates: FALSE
## Classes: 3
##     setosa versicolor  virginica 
##         50         50         50 
## Positive class: NA
```
---

### mlr - Train, predict, performance

```r
lrn = makeLearner("classif.rpart", minsplit = 5)
lrn
```

```
## Learner classif.rpart from package rpart
## Type: classif
## Name: Decision Tree; Short name: rpart
## Class: classif.rpart
## Properties: twoclass,multiclass,missings,numerics,factors,ordered,prob,weights,featimp
## Predict-Type: response
## Hyperparameters: xval=0,minsplit=5
```

```r
model = train(lrn, task, subset = seq(1, 150, by = 2))
model
```

```
## Model for learner.id=classif.rpart; learner.class=classif.rpart
## Trained on: task.id = iris; obs = 75; features = 4
## Hyperparameters: xval=0,minsplit=5
```
---

### mlr - Train, predict, performance

```r
pred = predict(model, task, subset = seq(2, 150, by = 2))
pred
```

```
## Prediction: 75 observations
## predict.type: response
## threshold: 
## time: 0.00
##    id  truth response
## 2   2 setosa   setosa
## 4   4 setosa   setosa
## 6   6 setosa   setosa
## 8   8 setosa   setosa
## 10 10 setosa   setosa
## 12 12 setosa   setosa
## ... (#rows: 75, #cols: 3)
```

```r
perf = performance(pred, measures = list(mmce, ber))
perf
```

```
##       mmce        ber 
## 0.05333333 0.05333333
```
---

### mlr - Resample
- Crossvalidation, subsampling, bootstrapping, etc., with a single command
- Get a container object with
    + Mean performances and performances per resampling iteration
    + Predictions
    + Models (if you want that)  

```r
lrn = makeLearner("classif.rpart", minsplit = 5)
rdesc = makeResampleDesc("CV", iters = 2) # or use "cv2" object
r = resample(lrn, task, rdesc, 
  measures = list(mmce, ber), models = TRUE) 
r
```

```
## Resample Result
## Task: iris
## Learner: classif.rpart
## Aggr perf: mmce.test.mean=0.0400000,ber.test.mean=0.0412196
## Runtime: 0.025003
```



---
### mlr - Benchmarking and Model Comparison
- Run one command to compare multiple learners on multiple data sets
- Get a (mergeable) container object with
    + Mean performances and performances per resampling iteration
    + Predictions
    + Models (if you want that)  

```r
# these are predefined in mlr for toying around:
tasks = list(iris.task, sonar.task)
learners = makeLearners(c("classif.rpart", "classif.randomForest"))
br = benchmark(learners, tasks, cv2)
br # again, you can access container in various ways
```

```
##         task.id           learner.id mmce.test.mean
## 1  iris-example        classif.rpart     0.06000000
## 2  iris-example classif.randomForest     0.04666667
## 3 Sonar-example        classif.rpart     0.27403846
## 4 Sonar-example classif.randomForest     0.18750000
```

---
### mlr - More features and outlook

Uncovered features

- Many different NA imputation techniques
- Many feature filters
- Imbalancy correction (e.g SMOTE) 
- Use wrappers to extend learner functionality
- Simple nested resampling  
- Efficient tuning: 
  Bayesian optimization with mlrMBO and iterated F-racing with irace
- Multi-criteria optimization
- Feature selection through wrappers (forward, backward)
- Ensembles, generic bagging and stacking

What will come next
- Anomaly detection / one-class Classification
- Functional data handling
- Time series forecasting
- Efficient pipelining (https://github.com/mlr-org/mlrCPO)

---
class:center,middle
# Back to OpenML
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
  }
});
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
